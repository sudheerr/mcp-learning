# Complete Walkthrough: What Happens When You Run `node mcp-client.js`

This document breaks down every step that occurs when you run the MCP client, explained in detail for beginners.

## The Big Picture

When you run `node mcp-client.js`, you're creating a system with three main components:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ    YOU     ‚îÇ ‚îÄ‚îÄ‚îÄ> ‚îÇ MCP CLIENT  ‚îÇ <‚îÄ‚îÄ> ‚îÇ  MCP SERVER ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                             ‚îÇ                               ‚îÇ
‚îÇ                             v                               ‚îÇ
‚îÇ                      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                        ‚îÇ
‚îÇ                      ‚îÇ CLAUDE API  ‚îÇ                        ‚îÇ
‚îÇ                      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                        ‚îÇ
‚îÇ                                                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Think of it like ordering food:**
- **YOU**: The customer who wants food (system information)
- **MCP CLIENT**: The waiter who takes your order and coordinates
- **CLAUDE API**: The chef who decides how to fulfill the order
- **MCP SERVER**: The kitchen that actually gets the ingredients (system data)

---

## Detailed Step-by-Step Walkthrough

### **STEP 1: Initialize Anthropic Client** (Lines 7-11)

```javascript
const anthropic = new Anthropic({
  apiKey: process.env.ANTHROPIC_API_KEY,
});
```

**What's happening:**
- Your code creates a connection object to talk to Anthropic's servers
- `process.env.ANTHROPIC_API_KEY` reads your API key from environment variables
- This API key is like your password to use Claude

**Real-world analogy:** Getting your phone and opening the Claude app - you need to be logged in (API key) to use it.

**Technical detail:** This creates an HTTP client that will make REST API calls to `https://api.anthropic.com`

---

### **STEP 2: Start the MCP Server Process** (Lines 16-19)

```javascript
const serverProcess = spawn("node", ["system-info-server/index.js"], {
  stdio: ["pipe", "pipe", "inherit"],
});
```

**What's happening:**
- `spawn` is a Node.js function that starts a new program/process
- It's like opening a new terminal window and running `node system-info-server/index.js`
- The server starts running in the background, separate from your client

**Breaking down `stdio: ["pipe", "pipe", "inherit"]`:**
- `stdio` stands for "standard input/output" - the three channels every program has:
  1. **stdin** (standard input) - how you send data TO the program
  2. **stdout** (standard output) - how the program sends data back to you
  3. **stderr** (standard error) - how the program reports errors

- **"pipe"** for stdin means: "I want to write data directly to the server's input"
- **"pipe"** for stdout means: "I want to read data directly from the server's output"
- **"inherit"** for stderr means: "Show the server's errors in my console"

**Real-world analogy:** Starting up a helper robot and giving it three communication channels - a way to give it commands, a way to hear its responses, and a way to hear if it has problems.

**What the server is doing now:**
- It's running and waiting
- It can receive JSON-RPC messages on its stdin
- It will respond with JSON-RPC messages on its stdout

---

### **STEP 3: Create the Transport Layer** (Lines 22-25)

```javascript
const transport = new StdioClientTransport({
  command: "node",
  args: ["system-info-server/index.js"],
});
```

**What's happening:**
- A "transport" is the communication method between client and server
- "Stdio" means communication happens via standard input/output (typing and reading text)
- This creates a dedicated communication channel to the server

**Why do we need this?**
- The MCP protocol needs a structured way to send messages
- The transport handles the low-level details: formatting messages, sending them, receiving responses
- It's like a postal service that knows how to deliver letters between client and server

**Real-world analogy:** Setting up a walkie-talkie channel. You could yell across the room, but a walkie-talkie is more reliable and structured.

**Other transport options (not used here):**
- HTTP transport: Communication via HTTP requests
- WebSocket transport: Real-time bidirectional communication
- SSE (Server-Sent Events): One-way streaming from server

---

### **STEP 4: Create the MCP Client** (Lines 27-34)

```javascript
const mcpClient = new Client(
  {
    name: "mcp-claude-client",
    version: "1.0.0",
  },
  {
    capabilities: {},
  }
);
```

**What's happening:**
- Creates an MCP client object with identity information
- `name` and `version` identify this client (useful for logging/debugging)
- `capabilities: {}` declares what features this client supports (empty = basic client)

**What is the MCP Client?**
- It's a JavaScript object that knows how to speak the MCP protocol
- It can send properly formatted MCP requests
- It can parse MCP responses
- It handles the handshake, tool discovery, and tool execution

**Real-world analogy:** Hiring a translator who speaks both English (your language) and MCP (the server's language).

**Capabilities you could add:**
- `roots`: If the client provides file system access
- `sampling`: If the client can help with AI sampling
- For this simple client, we don't provide any special capabilities

---

### **STEP 5: Connect to the MCP Server** (Line 37)

```javascript
await mcpClient.connect(transport);
```

**What's happening:**
This single line does a LOT behind the scenes. Let's break it down:

**5a. The Initialize Handshake**

The client sends this JSON-RPC message to the server:
```json
{
  "jsonrpc": "2.0",
  "id": 1,
  "method": "initialize",
  "params": {
    "protocolVersion": "2024-11-05",
    "capabilities": {},
    "clientInfo": {
      "name": "mcp-claude-client",
      "version": "1.0.0"
    }
  }
}
```

**5b. The Server Responds**

The server receives this and responds with:
```json
{
  "jsonrpc": "2.0",
  "id": 1,
  "result": {
    "protocolVersion": "2024-11-05",
    "capabilities": {
      "tools": {}
    },
    "serverInfo": {
      "name": "system-info-server",
      "version": "1.0.0"
    }
  }
}
```

**5c. What the handshake accomplishes:**
- Verifies both sides speak the same protocol version
- Exchanges capability information
- Confirms the connection is working
- Establishes trust between client and server

**Real-world analogy:** Two people meeting and saying:
- Client: "Hi, I'm mcp-claude-client version 1.0, I speak MCP protocol 2024-11-05"
- Server: "Hi, I'm system-info-server version 1.0, I also speak MCP protocol 2024-11-05. I can provide tools."
- Both: "Great! We can communicate!"

---

### **STEP 6: Discover Available Tools** (Lines 41-44)

```javascript
const toolsResult = await mcpClient.listTools();
console.log("\nüìã Available tools:", JSON.stringify(toolsResult.tools, null, 2));
```

**What's happening:**

**6a. Client sends request:**
```json
{
  "jsonrpc": "2.0",
  "id": 2,
  "method": "tools/list"
}
```

**6b. Server responds:**
```json
{
  "jsonrpc": "2.0",
  "id": 2,
  "result": {
    "tools": [
      {
        "name": "get_system_info",
        "description": "Get comprehensive system information including CPU, memory, and OS details",
        "inputSchema": {
          "type": "object",
          "properties": {
            "includeNetwork": {
              "type": "boolean",
              "description": "Include network interface information",
              "default": false
            }
          }
        }
      }
    ]
  }
}
```

**Why is this important?**
- The client now knows what tools are available
- Each tool has a name, description, and input schema (what parameters it accepts)
- This information will be passed to Claude so it knows what tools it can use

**Real-world analogy:** You ask the kitchen "What's on the menu?" and they give you a menu listing:
- **Dish name:** get_system_info
- **Description:** Get comprehensive system information...
- **Ingredients needed:** includeNetwork (optional, true/false)

---

### **STEP 7: Convert Tools to Anthropic Format** (Lines 47-51)

```javascript
const anthropicTools = toolsResult.tools.map((tool) => ({
  name: tool.name,
  description: tool.description,
  input_schema: tool.inputSchema,  // Note: renamed from inputSchema
}));
```

**What's happening:**
- MCP uses `inputSchema` (camelCase)
- Anthropic API uses `input_schema` (snake_case)
- We're converting from one format to the other

**Why different formats?**
- Different APIs, different conventions
- MCP follows JavaScript conventions (camelCase)
- Anthropic follows Python conventions (snake_case)
- The conversion is simple but necessary

**The converted format looks like:**
```javascript
[
  {
    name: "get_system_info",
    description: "Get comprehensive system information...",
    input_schema: {
      type: "object",
      properties: {
        includeNetwork: {
          type: "boolean",
          description: "Include network interface information",
          default: false
        }
      }
    }
  }
]
```

**Real-world analogy:** Translating a menu from French to English so Claude can read it.

---

### **STEP 8: Prepare the User Query** (Lines 54-62)

```javascript
const conversationHistory = [];
const userQuery = process.argv[2] || "What's my system information? Include network details if possible.";

console.log(`\nüí¨ User Query: "${userQuery}"\n`);

conversationHistory.push({
  role: "user",
  content: userQuery,
});
```

**What's happening:**
- `process.argv[2]` gets the first command-line argument (if you typed `node mcp-client.js "your question"`)
- If no argument, uses a default question
- Creates a `conversationHistory` array to track the entire conversation
- Adds your question as the first message

**Why track conversation history?**
- AI models are stateless - they don't remember previous messages
- Every request must include the full conversation context
- As we continue, this array will grow:
  ```
  [
    { role: "user", content: "What's my system info?" },
    { role: "assistant", content: [tool use request] },
    { role: "user", content: [tool result] },
    { role: "assistant", content: "Your system has..." }
  ]
  ```

**Real-world analogy:** Writing down the conversation so you can refer back to what was said.

---

### **STEP 9: Make Initial Request to Claude** (Lines 65-71)

```javascript
let response = await anthropic.messages.create({
  model: "claude-3-5-sonnet-20241022",
  max_tokens: 4096,
  tools: anthropicTools,
  messages: conversationHistory,
});
```

**What's happening:**

**9a. The request being sent to Anthropic:**
```json
{
  "model": "claude-3-5-sonnet-20241022",
  "max_tokens": 4096,
  "tools": [
    {
      "name": "get_system_info",
      "description": "Get comprehensive system information...",
      "input_schema": {...}
    }
  ],
  "messages": [
    {
      "role": "user",
      "content": "What's my system information? Include network details if possible."
    }
  ]
}
```

**9b. What Claude sees:**
- Your question
- A list of tools it can use
- For each tool: what it does and what parameters it needs

**9c. Claude's thinking process:**
1. "The user wants system information"
2. "I can't directly access system information - I'm just an AI"
3. "Wait! I have a tool called `get_system_info` that can do this"
4. "I should call that tool with `includeNetwork: true` since they mentioned network details"

**9d. Claude's response:**
```json
{
  "id": "msg_123abc",
  "type": "message",
  "role": "assistant",
  "content": [
    {
      "type": "tool_use",
      "id": "toolu_456def",
      "name": "get_system_info",
      "input": {
        "includeNetwork": true
      }
    }
  ],
  "stop_reason": "tool_use"
}
```

**Key fields:**
- `content`: Contains a tool_use block (not text!)
- `stop_reason`: "tool_use" means "I need to use a tool, come back after you execute it"
- `id`: Unique ID for this tool call so Claude can match it with results later

**Real-world analogy:**
- You ask the waiter: "What's today's special?"
- Waiter goes to the kitchen and says: "I need to check the specials board"
- Waiter hasn't given you an answer yet - they need to get information first

---

### **STEP 10: Check Stop Reason and Enter Tool Loop** (Line 77)

```javascript
while (response.stop_reason === "tool_use") {
```

**What's happening:**
- We check why Claude stopped responding
- If `stop_reason === "tool_use"`, Claude wants to use a tool
- The loop continues until Claude gives a final answer (`stop_reason === "end_turn"`)

**Possible stop reasons:**
- **"tool_use"**: Claude wants to call a tool
- **"end_turn"**: Claude has finished and provided a final answer
- **"max_tokens"**: Response hit the token limit (truncated)
- **"stop_sequence"**: Hit a custom stop sequence

**Why a loop?**
Claude might need multiple tools in sequence:
1. First call: Get system info
2. Second call: Get disk usage
3. Third call: Get running processes
4. Then: Provide final answer

**Real-world analogy:** The waiter might need to check multiple things in the kitchen before giving you a complete answer.

---

### **STEP 11: Add Claude's Response to History** (Lines 79-82)

```javascript
conversationHistory.push({
  role: "assistant",
  content: response.content,
});
```

**What's happening:**
- We add Claude's tool use request to the conversation history
- The conversation now looks like:
  ```javascript
  [
    {
      role: "user",
      content: "What's my system information? Include network details if possible."
    },
    {
      role: "assistant",
      content: [
        {
          type: "tool_use",
          id: "toolu_456def",
          name: "get_system_info",
          input: { includeNetwork: true }
        }
      ]
    }
  ]
  ```

**Why add this?**
- Claude needs to see its own previous messages
- When we send the tool result back, Claude needs to remember which tool it called
- The conversation history must be complete and sequential

**Real-world analogy:** Taking notes so you remember what was said: "Claude said it wants to use the get_system_info tool."

---

### **STEP 12: Process Each Tool Use** (Lines 85-103)

This is where the magic happens! Let's break it down in detail.

```javascript
const toolResults = [];
for (const content of response.content) {
  if (content.type === "tool_use") {
    console.log(`\nüîß Tool called: ${content.name}`);
    console.log(`Arguments: ${JSON.stringify(content.input, null, 2)}`);

    const result = await mcpClient.callTool({
      name: content.name,
      arguments: content.input,
    });

    console.log(`‚úÖ Tool result received`);

    toolResults.push({
      type: "tool_result",
      tool_use_id: content.id,
      content: result.content,
    });
  }
}
```

**12a. Loop through response content:**
- Claude's response can have multiple content blocks
- We look for blocks where `type === "tool_use"`

**12b. Log the tool call:**
```
üîß Tool called: get_system_info
Arguments: {
  "includeNetwork": true
}
```

**12c. Call the MCP server:**

When we do `await mcpClient.callTool(...)`, here's what happens:

**The client sends this JSON-RPC message to the server:**
```json
{
  "jsonrpc": "2.0",
  "id": 3,
  "method": "tools/call",
  "params": {
    "name": "get_system_info",
    "arguments": {
      "includeNetwork": true
    }
  }
}
```

**12d. The server executes the tool:**

Looking at your `system-info-server/index.js`, the server:
1. Receives the request
2. Checks `request.params.name === "get_system_info"` ‚úì
3. Extracts `includeNetwork` from arguments
4. Calls Node.js `os` module functions:
   - `os.cpus()` - Gets CPU information
   - `os.totalmem()` - Gets total memory
   - `os.freemem()` - Gets free memory
   - `os.platform()` - Gets OS platform (e.g., "linux")
   - `os.networkInterfaces()` - Gets network interfaces (if requested)
5. Formats the data into a nice object
6. Returns it

**12e. Server responds with:**
```json
{
  "jsonrpc": "2.0",
  "id": 3,
  "result": {
    "content": [
      {
        "type": "text",
        "text": "{\"os\":{\"platform\":\"linux\",\"type\":\"Linux\",\"release\":\"5.15.153.1\",\"architecture\":\"x64\",\"hostname\":\"your-pc\",\"uptime\":\"2d 5h 30m\"},\"cpu\":{\"model\":\"Intel(R) Core(TM) i7\",\"cores\":8,\"speed\":\"2400 MHz\"},\"memory\":{\"total\":\"15.50 GB\",\"free\":\"8.23 GB\",\"used\":\"7.27 GB\",\"usagePercentage\":\"46.90%\"},\"network\":{...}}"
      }
    ]
  }
}
```

**12f. Package the result:**

We create a tool_result object:
```javascript
{
  type: "tool_result",
  tool_use_id: "toolu_456def",  // Same ID Claude gave us
  content: [
    {
      type: "text",
      text: "{\"os\":{...},\"cpu\":{...},\"memory\":{...}}"
    }
  ]
}
```

**Why include tool_use_id?**
- Claude might call multiple tools
- The ID helps Claude match results to requests
- It's like a tracking number for a package

**Real-world analogy:**
1. Waiter goes to kitchen with your order (tool request)
2. Kitchen cooks the food (server executes tool)
3. Kitchen gives food to waiter with your order number (tool result with ID)
4. Waiter brings it back to you

---

### **STEP 13: Send Tool Results Back to Claude** (Lines 106-109)

```javascript
conversationHistory.push({
  role: "user",
  content: toolResults,
});
```

**What's happening:**
- We add the tool results to the conversation history
- Note: role is "user" (not "assistant")!

**Why role "user"?**
This might seem confusing, but here's why:
- In Claude's API, the conversation alternates: user, assistant, user, assistant...
- Tool results are considered "user" messages because they're information coming from outside Claude
- The pattern is:
  ```
  user: "What's my system info?"
  assistant: [tool_use request]
  user: [tool_result]  ‚Üê This is YOU providing the result back
  assistant: "Your system has..."
  ```

**The conversation now looks like:**
```javascript
[
  { role: "user", content: "What's my system information?..." },
  { role: "assistant", content: [{ type: "tool_use", ... }] },
  {
    role: "user",
    content: [
      {
        type: "tool_result",
        tool_use_id: "toolu_456def",
        content: [{ type: "text", text: "{...system data...}" }]
      }
    ]
  }
]
```

**Real-world analogy:** You're delivering the information the waiter requested back to them.

---

### **STEP 14: Continue Conversation with Tool Results** (Lines 112-119)

```javascript
response = await anthropic.messages.create({
  model: "claude-3-5-sonnet-20241022",
  max_tokens: 4096,
  tools: anthropicTools,
  messages: conversationHistory,
});

console.log(`\nü§ñ Claude's response:`);
console.log(`Stop reason: ${response.stop_reason}`);
```

**What's happening:**

**14a. Send the updated conversation to Claude:**
- Same API call as before
- But now `messages` includes the tool result
- Claude can see what the tool returned

**14b. Claude's thinking process:**
1. "Oh good, I got the system information back"
2. "Let me read this data..."
3. "I see 15.50 GB total RAM, 8 cores, Linux OS, network interfaces..."
4. "Now I can formulate a helpful answer for the user"

**14c. Claude's response this time:**
```json
{
  "id": "msg_789ghi",
  "type": "message",
  "role": "assistant",
  "content": [
    {
      "type": "text",
      "text": "Based on the system information, here's what I found:\n\n**Operating System:**\n- Platform: Linux\n- Release: 5.15.153.1\n- Architecture: x64\n- Hostname: your-pc\n- Uptime: 2 days, 5 hours, 30 minutes\n\n**CPU:**\n- Model: Intel(R) Core(TM) i7\n- Cores: 8\n- Speed: 2400 MHz\n\n**Memory:**\n- Total: 15.50 GB\n- Used: 7.27 GB (46.90%)\n- Free: 8.23 GB\n\n**Network Interfaces:**\n[detailed network info]\n\nYour system appears to be running well with plenty of available memory!"
    }
  ],
  "stop_reason": "end_turn"
}
```

**Notice:**
- `content` is now text (not tool_use!)
- `stop_reason` is "end_turn" (not "tool_use")
- Claude has formatted the raw JSON into friendly, readable text

**14d. Exit the loop:**
- `stop_reason === "end_turn"` so we exit the `while` loop
- No more tools needed!

**Real-world analogy:** The waiter has all the information and gives you the final answer about today's specials.

---

### **STEP 15: Display Final Answer** (Lines 123-128)

```javascript
console.log("\nüìù Final Answer:");
for (const content of response.content) {
  if (content.type === "text") {
    console.log(content.text);
  }
}
```

**What's happening:**
- Loop through the response content
- Print any text blocks to the console
- Skip non-text blocks (there shouldn't be any at this point)

**What you see on screen:**
```
üìù Final Answer:
Based on the system information, here's what I found:

**Operating System:**
- Platform: Linux
- Release: 5.15.153.1
...
```

**Real-world analogy:** Reading the waiter's final answer out loud.

---

### **STEP 16: Cleanup** (Lines 131-133)

```javascript
await mcpClient.close();
serverProcess.kill();
console.log("\nüëã Done!");
```

**What's happening:**

**16a. `await mcpClient.close()`:**
- Sends a shutdown message to the MCP server
- Cleanly closes the connection
- Like saying "goodbye" before hanging up the phone

**16b. `serverProcess.kill()`:**
- Terminates the server process
- Frees up system resources
- The server stops running

**16c. Print goodbye message**

**Real-world analogy:**
- Thanking the waiter
- Leaving the restaurant
- Turning off the lights

---

## The Complete Flow: A Timeline

Let me show you the complete timeline with all messages:

```
[0.0s] You run: node mcp-client.js

[0.1s] CLIENT ‚Üí Creates Anthropic API client
[0.2s] CLIENT ‚Üí Starts MCP server subprocess
[0.3s] CLIENT ‚Üí Creates MCP client

[0.4s] CLIENT ‚Üí SERVER: "initialize" (handshake)
[0.5s] SERVER ‚Üí CLIENT: "I'm system-info-server, I provide tools"

[0.6s] CLIENT ‚Üí SERVER: "tools/list" (what tools do you have?)
[0.7s] SERVER ‚Üí CLIENT: "I have get_system_info tool"

[0.8s] CLIENT ‚Üí Converts tools to Anthropic format
[0.9s] CLIENT ‚Üí Prepares user query

[1.0s] CLIENT ‚Üí CLAUDE: "What's my system info?" + tool list
[1.5s] CLAUDE ‚Üí CLIENT: "I want to use get_system_info tool"

[1.6s] CLIENT ‚Üí SERVER: "tools/call get_system_info"
[1.7s] SERVER ‚Üí Reads os.cpus(), os.totalmem(), etc.
[1.8s] SERVER ‚Üí CLIENT: Returns system data JSON

[1.9s] CLIENT ‚Üí CLAUDE: "Here's the tool result"
[2.3s] CLAUDE ‚Üí CLIENT: "Your system has 15.50 GB RAM, 8 cores..."

[2.4s] CLIENT ‚Üí Displays answer to you
[2.5s] CLIENT ‚Üí Closes connection and kills server
[2.6s] Done!
```

---

## Key Concepts Explained

### 1. **What is MCP (Model Context Protocol)?**

MCP is a **standard protocol** for AI models to interact with external tools and data sources.

**Without MCP:**
- Every AI model has its own way of calling tools
- You'd need custom code for Claude, GPT-4, Gemini, etc.
- Can't reuse tools across different AI systems

**With MCP:**
- One standard protocol everyone follows
- Write your tool once, works with any MCP-compatible AI
- Like USB - one standard, works everywhere

**Your system-info-server:**
- Speaks MCP
- Could be used by Claude, GPT-4, or any other MCP client
- The server doesn't even know it's talking to Claude!

---

### 2. **What are Tools (Function Calling)?**

AI models can't directly:
- Access files on your computer
- Make API calls
- Read databases
- Get real-time information

Instead, they can **request** to use tools:
1. You give the AI a list of available tools
2. AI decides if it needs to use a tool
3. AI sends a structured request: "Please call tool X with parameters Y"
4. **You** (the client code) execute the tool
5. You send the results back to the AI
6. AI incorporates results into its response

**Security benefit:**
- AI never directly executes code
- You control what tools are available
- You control how tools are executed
- You can validate/sanitize inputs

---

### 3. **Why Keep Conversation History?**

AI models are **stateless** - they have no memory between requests.

**Each API call is independent:**
```javascript
// Call 1
anthropic.messages.create({ messages: [{ role: "user", content: "Hi" }] })
// Claude responds: "Hello!"

// Call 2
anthropic.messages.create({ messages: [{ role: "user", content: "What did I say?" }] })
// Claude responds: "I don't know, this is the first message I've seen"
```

**To have a conversation, send the full history:**
```javascript
anthropic.messages.create({
  messages: [
    { role: "user", content: "Hi" },
    { role: "assistant", content: "Hello!" },
    { role: "user", content: "What did I say?" }
  ]
})
// Claude responds: "You said 'Hi'"
```

**In our tool use flow:**
- We need to send: user question ‚Üí assistant tool request ‚Üí user tool result ‚Üí assistant answer
- Each request includes everything that came before
- That's why we maintain `conversationHistory` array

---

### 4. **The Tool Use Loop**

Claude might need multiple tools to answer a question:

**Example: "Analyze my largest files"**

```
Loop 1:
  Claude: "I need to list files" ‚Üí calls list_files tool
  You: [returns file list]

Loop 2:
  Claude: "I need to get sizes" ‚Üí calls get_file_sizes tool
  You: [returns sizes]

Loop 3:
  Claude: "I need to read the largest file" ‚Üí calls read_file tool
  You: [returns file content]

Loop exits:
  Claude: "Your largest file is config.json (5MB) containing..."
```

That's why we have `while (response.stop_reason === "tool_use")` - keep looping until Claude has all the information it needs.

---

## What Makes This Powerful?

### 1. **Local Execution**
- Tools run on YOUR computer
- Access to YOUR filesystem, YOUR databases, YOUR APIs
- No need to upload data to the cloud

### 2. **Privacy**
- Raw system data never goes to Anthropic
- Only the formatted results are sent
- You control what data leaves your machine

### 3. **Extensibility**
You can add any tool you want:
```javascript
{
  name: "search_database",
  description: "Search our company database",
  input_schema: { ... }
}

{
  name: "send_email",
  description: "Send an email via our SMTP server",
  input_schema: { ... }
}

{
  name: "deploy_code",
  description: "Deploy code to production",
  input_schema: { ... }
}
```

### 4. **Modularity**
- MCP server can be used by ANY MCP client
- Not locked into Claude
- Could use the same server with GPT-4, Gemini, local models, etc.

### 5. **Agentic Behavior**
- Claude **decides** when to use tools
- Claude **chooses** appropriate parameters
- You just ask a question in natural language
- Claude figures out the rest

---

## Experiment to Understand Better

Try running with different questions and watch the console output:

### Experiment 1: No Tools Needed
```bash
node mcp-client.js "What is 2+2?"
```

**Expected behavior:**
- Claude won't use any tools
- `stop_reason` will be "end_turn" immediately
- No tool use loop

**Why?** Claude can answer math questions without external data.

---

### Experiment 2: Simple Tool Use
```bash
node mcp-client.js "How much RAM does my computer have?"
```

**Expected behavior:**
- Claude uses `get_system_info` tool
- Tool called with `includeNetwork: false` (not needed for this question)
- Gets result, formats just the memory part

**Watch for:**
- Claude's reasoning about what data it needs
- How it extracts just the relevant info from the tool result

---

### Experiment 3: Multiple Data Points
```bash
node mcp-client.js "Give me a detailed report of my system"
```

**Expected behavior:**
- Claude uses `get_system_info` with `includeNetwork: true`
- Formats all sections nicely
- Maybe even draws conclusions (e.g., "your system is under light load")

---

### Experiment 4: Tool Not Helpful
```bash
node mcp-client.js "What's the weather like?"
```

**Expected behavior:**
- Claude might try the tool anyway (to check)
- Or might respond "I don't have access to weather data"
- The system-info tool won't help with weather!

**What this teaches:** Claude is smart but not perfect. It might try tools that won't help, or realize it doesn't have the right tools.

---

## Common Questions

### Q: Does Claude see my MCP server code?
**A:** No! Claude only sees:
- Tool names and descriptions
- Input schemas
- Tool results (the data you send back)

Claude doesn't see your server implementation at all.

---

### Q: Can Claude call tools without asking?
**A:** Claude doesn't "ask" you for permission - it just requests to use tools. Your code automatically executes them. If you want confirmation, you'd need to add that to your client code.

---

### Q: What if Claude calls a tool that doesn't exist?
**A:** The MCP client will return an error, and Claude will see that error. It will likely apologize and try a different approach.

---

### Q: Can Claude call multiple tools in parallel?
**A:** In a single response, Claude can request multiple tools. Your client code would execute them (you could do this in parallel). Then Claude gets all results at once.

---

### Q: What happens if a tool takes a long time?
**A:** Your code waits (the `await` pauses execution). Claude doesn't know or care how long it takes. From Claude's perspective, it's instant.

---

### Q: Could I use this with GPT-4 instead of Claude?
**A:** Yes! You'd need to:
1. Keep the MCP server as-is (it's model-agnostic)
2. Replace the Anthropic API calls with OpenAI API calls
3. Convert tools to OpenAI's format
4. Handle OpenAI's tool calling format

The MCP server wouldn't change at all!

---

## Summary

When you run `node mcp-client.js`:

1. ‚úÖ **Setup:** Create API client, start MCP server, connect
2. ‚úÖ **Discovery:** Ask server what tools it has
3. ‚úÖ **Initial request:** Send your question + tool list to Claude
4. ‚úÖ **Tool use loop:** Claude requests tools ‚Üí you execute ‚Üí send results back
5. ‚úÖ **Final answer:** Claude formulates natural language response
6. ‚úÖ **Cleanup:** Close connections, shut down server

**The magic:** Claude acts as an intelligent coordinator, deciding when and how to use your local tools to answer questions in natural language.

**The power:** You can extend this with ANY tools you want - file access, database queries, API calls, hardware control, etc.

**The future:** This is the foundation of agentic AI systems that can interact with the real world through tools.
